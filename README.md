# Matching, Поиск ближайшего соседа  

В данном проекте было необходимо разработать алгоритм который для всех товаров из списка может 
 предложить несколько вариантов наиболее похожих товаров из имеющеся базы данных. В моём распоряжении 
находилась база данных с 3 милионами товаров и 72 признаками для каждого, тринировочный набор данных и 
данные для валидации.  Заказщик предворительно зашифровал все данные, поэтому анализ признаков не представлялся возможным.

## Данные

- *base.csv* - анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.
- *target.csv -* обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …) , вектор признаков И id товара из *base.csv*, который максимально похож на него (по мнению экспертов).
- *validation.csv* - датасет с товарами (уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из *base.csv*
- *validation_answer.csv* - правильные ответы к предыдущему файлу.  

Задача была разбита на два этапа. В первом была применена библиотека от раззработанная Facebook - 
"Facebook AI Similarity Search". Необходимо было выбрать n кандидатов для каждого запроса из target и на втором 
этапе с помощью модели CatBoostClassifier проранжировать их. 

На первом этапе (Файл Matching.ipynb) было проанализированно несколько вариантов индексации и квантования признаков:
инферированный индекс (IVF), product quantization (PQ), инферированный мульти индекс (IMI), их различные комбинации,
а также методы Refine, RFlat и OPQ. Наилучший результат в index_factory показала строка "OPQ32,IMI2x8,PQ32" со значением метрики 
accuracy@5 = 82 для 200 ближайших соседей и 84.5 для 500 и nprobe = 10000. Хочется отметить несколько интересных 
фактов:
1) Применение метода масштабирования признаков StandardScaler в последствии даёт меньший результат, чем MinMaxScaler.
2) Для IVFPQ можно разбить вектор признаков на две части и для каждой обучить свою модель faiss. После объединения предсказаний и удаления 
дубликатов, можно получить метрику на 1% выше, чем для одной модели faiss для одинакового выходного колическва соседей. 
Данный метод плохо работает для IVFFlat и HNSWFlat.  
3) Некоторые признаки сильно ухудшают работу faiss, поэтому первый этап проводился без них.

## Итоги

| количество соседей | Accuracy@n после первого этапа | Время выполнения на валидации | Accuracy@5 |
|:----------------:|:----------------:|:---------:|:----------------:|
| 500 | asdadad| По центру | По правому краю |
| 200 | asdadad| текст | текст |
| 100 | asdadad| текст | текст |


